<!DOCTYPE HTML>
<!--
	Arcana by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Big Data Projects</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header">

					<!-- Logo -->
						<h1><a href="index.html" id="logo">Eric Brown - Data Analytics Portfolio</a></h1>

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Home</a></li>
								<li class="current"><a href="left_sidebar1.html">Big Data Projects</a></li>
								<li><a href="left_sidebar2.html">Machine Learning Projects</a></li>
								<li><a href="left_sidebar3.html">Web & Game Applications</a></li>
								<li><a href="left_sidebar4.html">Statistical Programming Projects</a></li>
								<li><a href="lef_sidebar5.html">SQL Projects</a></li>
								<li><a href="left_sidebar6.html">Deep Learning Projects</a></li>
								<li><a href="left_sidebar7.html">Data Visualization Projects</a></li>
							</ul>
						</nav>

				</div>

			<!-- Main -->
				<section class="wrapper style1">
					<div class="container">
						<div class="row gtr-200">
							<div class="col-4 col-12-narrower">
								<div id="sidebar">

									<!-- Sidebar -->

										<section style="border-top:thick rgb(210, 180, 140) solid;border-bottom:thick rgb(210, 180, 140) solid;padding-left:2px;padding-right:2px;">
											<h3>Interesting Big Data Quotes</h3>
											<p style="color:gray;">“The goal is to turn data into information, and information into insight.”</p>
												<p>– Carly Fiorina</p>
											<p style="font-size:14 px;">“Hiding within those mounds of data is the knowledge that could change the life of a patient, or change the world.”</p>
											<p>– Atul Butte</p>
										</section>

										<section>
											<h3>Links to Big Data Projects</h3>
											<ul class="links">
												<li><a href="https://github.com/downtownEB24/DataScience_Projects/blob/main/MapReduce_Assignment.pdf">MapReduce Poem Analysis Assigment</a></li>
												<li><a href="https://github.com/downtownEB24/DataScience_Projects/blob/main/Apache_Pig_Assignment.pdf">Apache Pig Text Data Assigment</a></li>
												<li><a href="https://github.com/downtownEB24/DataScience_Projects/blob/main/Apache_Hive_Assignment.pdf">Apache Hive Sales Data Assignment</a></li>
												<li><a href="https://github.com/downtownEB24/DataScience_Projects/blob/main/Project_Part1.pdf">US Election Contribution Data-warehouse Project</a></li>
												<li><a href="https://github.com/downtownEB24/DataScience_Projects/blob/main/project_part2.pdf">US Election Contribution Hadoop Big Data Solution Project</a></li>
											</ul>
											<footer>
												<a href="index.html" class="button">Homepage: Quick Link</a>
											</footer>
										</section>

								</div>
							</div>
							<div class="col-8  col-12-narrower imp-narrower">
								<div id="content">

									<!-- Content -->

										<article>
											<header>
												<h2>Key Big Data Projects/Assignments</h2>
												<p>Using Frameworks & Languages such MapReduce, Pig, Hive, PostgreSQL</p>
											</header>

											<span class="image featured"><img src="images/big_data.jpg" alt="big data picture" /></span>


											<h3>Big Data Projects</h3>
											<a href="https://github.com/downtownEB24/DataScience_Projects/blob/main/MapReduce_Assignment.pdf">Using MapReduce Framework to analysis series of poem data</a>
											<p><b>Assignment Objective:</b>
											In this assignment I used MapReduce to perform data processing tasks on a collection of poem datasets in a Hadoop docker environment. The first task involved me running a MapReduce job to count the lines in a collection of text files (poem data). Then in the second task, I had to modify the MapReduce job to count words by their lengths. This included implementing Mapper, Reducer, and Combiner functions to perform various types of aggregations and counts based on custom logic.</p>

											<a href="https://github.com/downtownEB24/DataScience_Projects/blob/main/Apache_Pig_Assignment.pdf">Analyzing Text Data with Apache Pig</a>
											<p><b>Assignment Objective:</b>
                                                In this assignment, I used Apache Pig to process data on a Hadoop server, transforming Pig Latin scripts into MapReduce jobs. Unlike my previous assignment, where I wrote extensive MapReduce code to analyze the poem datasets, this time I was able to simplify the process by writing a few concise scripts in Pig Latin. These scripts allowed me to count various word attributes with ease. I also felt more comfortable working in Pig Latin, as it uses commands similar to SQL, making the process more intuitive.
                                            </p>
											
											<a href="https://github.com/downtownEB24/DataScience_Projects/blob/main/Apache_Hive_Assignment.pdf">Sales Data Analysis using Apache Hive</a><br>
											<p><b>Assignment Objective:</b>
                                                In this assignment, I used Apache Hive to analyze a superstore sales dataset, focusing on insights like sales by customer type, regional sales trends, and seasonal order patterns. After creating a Hive table to organize the data, I ran a series of complex queries that revealed top-performing customer segments, regions with high order volumes, and patterns in high-value orders.</p>

											<a href="https://github.com/downtownEB24/DataScience_Projects/blob/main/Project_Part1.pdf">Data Warehouse Project using PostgreSQL</a><br>
                                            <b> External Datasets used in program:</b></br>
                                            <a href="https://github.com/downtownEB24/DataScience_Projects/blob/main/project_excel_files.zip">2020 Election Contribution Data</a>
											<p><b>Project Objective:</b>
											The goal of this project was to create a data warehouse in PostgreSQL to analyze 2020 U.S. election contributions from data sourced from the ProPublica website. Key steps included:</p>
                                            <ol>
                                                <li><strong>Data Warehouse Design: </strong>A star schema is used, with fact and dimension tables representing aspects like contributors' state, city, occupation, and employer.</li>
                                                <li><strong>ETL Process: </strong>Data is extracted, transformed, and loaded (ETL) using KNIME, a tool that simplifies ETL with a visual interface. This involves filtering, joining, and converting data to match the warehouse structure.</li>
                                                <li><strong>Business Questions: </strong>The project aims to answer questions such as which states or companies contributed the most and what demographics supported each political party.</li>
                                                <li><strong>Reporting: </strong>Data is aggregated to show trends in contributions, and visualizations like bar charts, pie charts, and tables are created to highlight key insights.</li>
                                            </ol>
                                            <p>The project demonstrates how a relational database can be used effectively for data analysis in a structured, SQL-compliant environment, setting the stage for a comparison with a Hadoop-based big data approach in the next phase.</p>

											<a style="font-size:18px;" href="https://github.com/downtownEB24/DataScience_Projects/blob/main/project_part2.pdf">Hadoop-based Big Data Project</a><br>
											<p><b>Project Objective:</b>
											The goal of this project was to expand on the data warehouse project from Part 1 of this complete assignment and implement a Hadoop big data solution to process the 2020 U.S. election contributions data. Key Comparisons in Solutions:</p>
                                            <ol>
                                                <li><strong>Data Schema Differences: </strong>While the PostgreSQL data warehouse used a star schema, the Hadoop implementation uses a simpler structure, with one main fact table.</li>
                                                <li><strong>ETL & Apache Pig: </strong>The project uses Pig scripts for data transformation, such as removing unwanted columns, creating new fields, and cleaning missing data. Pig scripts simplify the process compared to writing MapReduce code directly.</li>
                                                <li><strong>Data Analysis in Hive: </strong>After loading the cleaned data into Hive, queries were performed to answer similar business questions as in Part 1. Hive’s SQL-like syntax, HiveQL, made it easy to aggregate and filter data for insights.</li>
                                            </ol>
                                            <p>From this project I was able to discover how Hadoop’s distributed nature offers scalability and efficiency for big data, while PostgreSQL provided faster setup for structured data with schema constraints.</p>
										</article>

								</div>
							</div>
						</div>
					</div>
				</section>



					<!-- Copyright -->
						<div class="copyright">
							<ul class="menu">
								<li>&copy; Untitled. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
								<li>Big Data Image: <a href="https://wordlift.io/blog/en/entity/big-data/">on Wordlift</a></li>
							</ul>
						</div>

				</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>